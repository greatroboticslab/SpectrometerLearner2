{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J-1hOm7rQWxf"},"outputs":[],"source":["from modules.csv_processor import CSVProcessor\n","from modules.data_augmentation import DataAugmentation\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import csv\n","from sklearn.compose import ColumnTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["processor = CSVProcessor(\"./Dataset\")\n","X_train, y_train = processor.split()\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n","\n","preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), numerical_cols)])\n","\n","# Fit and transform the training data\n","X_train_scaled = pd.DataFrame(preprocessor.fit_transform(X_train), columns=X_train.columns)\n","\n","# Transform the test data\n","X_test_scaled = pd.DataFrame(preprocessor.transform(X_test), columns=X_test.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":185,"status":"ok","timestamp":1689642679216,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"adVgf2AoX4hO"},"outputs":[],"source":["# 4. Split the Data into Training and Test Sets\n","X_train, X_test = X_train_scaled, X_test_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_augmentation = DataAugmentation(X_train, y_train, num_augmented_samples=3000)\n","X_train, y_train = data_augmentation.apply_data_augmentation()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1689643027739,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"VrX-Ry56dZDQ"},"outputs":[],"source":["input_shape = X_train.shape[1]\n","num_classes = len(np.unique(y_train))\n","\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(input_shape,)),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGv_B9gdd4yA"},"outputs":[],"source":["# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model to the training data\n","model.fit(X_train, y_train, batch_size=4, epochs=100, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpiSxmIQd6Sb"},"outputs":[],"source":["# Evaluate the model on the testing data\n","loss, accuracy = model.evaluate(X_test, y_test)\n","\n","print(\"Testing Accuracy:\", accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNH9L611TIMqjHXZi4JuRRj","mount_file_id":"1K4x9qiERmw_caIw3YMu17mct8izpcloD","name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
