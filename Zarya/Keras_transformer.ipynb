{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J-1hOm7rQWxf"},"outputs":[],"source":["from csv_processor import CSVProcessor\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2244,"status":"ok","timestamp":1689642119005,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"9_ItjDe-Zi0b"},"outputs":[],"source":["processor = CSVProcessor(\"../Training Data\")\n","X_train, y_train = processor.split()\n","#processor = CSVProcessor(\"../Testing Data\")\n","#X_test, y_test = processor.split()\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2315,"status":"ok","timestamp":1689642615556,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"9Yia6gneilvm"},"outputs":[],"source":["def apply_data_augmentation(X_train, y_train, num_augmented_samples=1000):\n","    augmented_data = []\n","    augmented_labels = []\n","\n","    for i in range(num_augmented_samples):\n","        # Randomly select an index from the original data\n","        index = np.random.randint(len(X_train))\n","        original_sample = X_train.iloc[index]\n","        label = y_train[index]\n","\n","        # Apply data augmentation (you can customize these operations)\n","        augmented_sample = original_sample + np.random.normal(0, 0.1, original_sample.shape)  # Adding random noise\n","        augmented_sample *= np.random.uniform(0.9, 1.1)  # Scaling by a random factor\n","        if np.random.rand() < 0.5:\n","            augmented_sample = np.flip(augmented_sample)  # Randomly flipping the sample\n","\n","        augmented_data.append(augmented_sample)\n","        augmented_labels.append(label)\n","\n","    # Convert the augmented data and labels to numpy arrays\n","    augmented_data = np.array(augmented_data)\n","    augmented_labels = np.array(augmented_labels)\n","\n","    # Concatenate the original data with the augmented data\n","    X_train_augmented = np.concatenate((X_train.values, augmented_data), axis=0)\n","    y_train_augmented = np.concatenate((y_train, augmented_labels), axis=0)\n","\n","    return X_train_augmented, y_train_augmented\n","\n","# Assuming X_train and y_train are your original data in pandas DataFrames\n","X_train_augmented, y_train_augmented = apply_data_augmentation(X_train.reset_index(drop=True), y_train, num_augmented_samples=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1689642672252,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"7sh2xqENhDg9"},"outputs":[],"source":["X_train, y_train = X_train_augmented, y_train_augmented"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1689642675815,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"GvOmWVPTX4X7","outputId":"d19366f6-1582-4b13-c32b-3f00a3a7bd27"},"outputs":[],"source":["scaler = StandardScaler()\n","\n","# Fit the scaler on the training features and transform them\n","X_train_scaled = scaler.fit_transform(X_train)\n","\n","# Transform the test features using the fitted scaler\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":185,"status":"ok","timestamp":1689642679216,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"adVgf2AoX4hO"},"outputs":[],"source":["# 4. Split the Data into Training and Test Sets\n","X_train, X_test = X_train_scaled, X_test_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1730464,"status":"ok","timestamp":1689639192352,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"7YnQCmXUziZh","outputId":"f8b5ae60-20b6-4cb6-c59f-78e1a99f590e"},"outputs":[],"source":["# Test different hyperparameter combinations for the Keras model\n","\"\"\"\n","# List of hyperparameter combinations\n","input_shape = X_train.shape[1]\n","num_classes = len(np.unique(y_train))\n","param_combinations = [\n","    {'hidden_layers': 1, 'hidden_units': 64, 'dropout': 0.5, 'batch_size': 4, 'epochs': 100},\n","    {'hidden_layers': 2, 'hidden_units': 128, 'dropout': 0.5, 'batch_size': 8, 'epochs': 150},\n","    {'hidden_layers': 3, 'hidden_units': 256, 'dropout': 0.5, 'batch_size': 16, 'epochs': 200},\n","]\n","\n","# Create an empty list to store the results\n","results = []\n","\n","# Iterate over each parameter combination\n","for params in param_combinations:\n","    # Create the model with the given parameters\n","    model = Sequential()\n","    for _ in range(params['hidden_layers']):\n","        model.add(Dense(params['hidden_units'], activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(params['dropout']))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    \n","    # Compile and fit the model\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], verbose=1)\n","    \n","    # Evaluate the model on the testing data\n","    loss, accuracy = model.evaluate(X_test, y_test)\n","    \n","    # Append the parameters and accuracy to the results list\n","    result = {\n","        'hidden_layers': params['hidden_layers'],\n","        'hidden_units': params['hidden_units'],\n","        'dropout': params['dropout'],\n","        'batch_size': params['batch_size'],\n","        'epochs': params['epochs'],\n","        'accuracy': accuracy\n","    }\n","    results.append(result)\n","\n","# Save the results to a CSV file\n","filename = 'model_results.csv'\n","keys = results[0].keys()\n","with open(filename, 'w', newline='') as file:\n","    writer = csv.DictWriter(file, keys)\n","    writer.writeheader()\n","    writer.writerows(results)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1689643027739,"user":{"displayName":"Zarya Amin","userId":"00381040780052705520"},"user_tz":300},"id":"VrX-Ry56dZDQ"},"outputs":[],"source":["input_shape = X_train.shape[1]\n","num_classes = len(np.unique(y_train))\n","\n","model = Sequential([\n","    Dense(64, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(32, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGv_B9gdd4yA"},"outputs":[],"source":["# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model to the training data\n","model.fit(X_train, y_train, batch_size=4, epochs=200, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpiSxmIQd6Sb"},"outputs":[],"source":["# Evaluate the model on the testing data\n","loss, accuracy = model.evaluate(X_test, y_test)\n","\n","print(\"Testing Accuracy:\", accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNH9L611TIMqjHXZi4JuRRj","mount_file_id":"1K4x9qiERmw_caIw3YMu17mct8izpcloD","name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
